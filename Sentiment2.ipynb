{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/mick/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mick/anaconda/envs/ee227-py3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # For sentiment analysis\n",
    "import pickle # For loaded dataset from pickle file\n",
    "import tqdm # Progress bar\n",
    "from collections import Counter # Handy addon\n",
    "from pprint import pprint # Useful to print JSON objects\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57767 articles were loaded\n",
      "Example article:\n",
      "{b'news_topic': b'ISIS War',\n",
      " 'introductions': [{'person': 'Bashar al-Assad',\n",
      "                    'text': 'President',\n",
      "                    'wdid': 'Q44329'},\n",
      "                   {'person': 'Emile Hokayem', 'text': 'in Foreign Policy'},\n",
      "                   {'person': 'Ahrar al Sham',\n",
      "                    'text': 'the most important groups',\n",
      "                    'wdid': 'Q860943'},\n",
      "                   {'person': 'Vladimir Putin',\n",
      "                    'text': 'Russian President',\n",
      "                    'wdid': 'Q7747'},\n",
      "                   {'person': 'Barack Obama',\n",
      "                    'text': 'U.S. President',\n",
      "                    'wdid': 'Q76'},\n",
      "                   {'person': 'Osama Abu Zeid',\n",
      "                    'text': 'a senior adviser to the moderate Free Syrian '\n",
      "                            'Army'},\n",
      "                   {'person': 'Op-Ed',\n",
      "                    'text': 'for The Washington Post',\n",
      "                    'wdid': 'Q2602337'},\n",
      "                   {'person': 'Nicholas Burns',\n",
      "                    'text': 'two former senior officials',\n",
      "                    'wdid': 'Q7025139'},\n",
      "                   {'person': 'Natalie Nougayrède',\n",
      "                    'text': 'Guardian columnist',\n",
      "                    'wdid': 'Q6430048'},\n",
      "                   {'person': 'Natalie Nougayrède',\n",
      "                    'text': '',\n",
      "                    'wdid': 'Q6430048'}],\n",
      " 'pubtime': datetime.datetime(2016, 2, 8, 15, 18, 6),\n",
      " 'source': 'cnn.com',\n",
      " 'title': 'Aleppo siege marks upheaval on Syrian battlefield',\n",
      " 'url': 'http://www.cnn.com/2016/02/07/middleeast/syria-aleppo-siege/index.html?eref=rss_world'}\n"
     ]
    }
   ],
   "source": [
    "# This loads the file that you want, might take several seconds (up to a minute)\n",
    "\n",
    "with open(\"news_sentiment.pickle\", \"rb\") as f:\n",
    "    articles = pickle.load(f, encoding='bytes')\n",
    "print(len(articles), \"articles were loaded\")\n",
    "print(\"Example article:\")\n",
    "pprint(articles[1040])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39206  articles from ISIS War and  18561 articles from Brexit were loaded\n"
     ]
    }
   ],
   "source": [
    "# separate articles from the two stories\n",
    "ISIS_articles = []\n",
    "Brexit_articles = []\n",
    "for a in articles:\n",
    "    if a[b\"news_topic\"] == b'ISIS War':\n",
    "        ISIS_articles.append(a)\n",
    "    else:\n",
    "        Brexit_articles.append(a)\n",
    "        \n",
    "print(len(ISIS_articles), \" articles from ISIS War and \", len(Brexit_articles), \"articles from Brexit were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get only articles from one story, you can change this\n",
    "articles = ISIS_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract introductions, and obtain their sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b50e758b5435092939d3f4254e5d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "total_introductions = []\n",
    "for a in articles:\n",
    "    for intro in a.get('introductions', []):\n",
    "        intro['source'] = a['source']\n",
    "        total_introductions.append(intro)\n",
    "\n",
    "for intro in tqdm.tqdm_notebook(total_introductions):\n",
    "    intro['sentiment'] = analyzer.polarity_scores(intro['text'])['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Entity mentionned: James Terry\n",
      "commander of Joint Task Force Operation \n",
      " Inherent Resolve\n",
      "Sentiment: 0.3818\n",
      "---------------\n",
      "Entity mentionned: Tadamun\n",
      "the last rebel - held district of Damascus\n",
      "Sentiment: -0.1531\n",
      "---------------\n",
      "Entity mentionned: Erdogan\n",
      "who won a third consecutive election in 2011 with 50 percent support\n",
      "Sentiment: 0.7506\n",
      "---------------\n",
      "Entity mentionned: Lakhdar Brahimi\n",
      "his special envoy , , who told reporters\n",
      "Sentiment: 0.4019\n",
      "---------------\n",
      "Entity mentionned: Alawi\n",
      "whose country is a member of the wealthy six - member bloc\n",
      "Sentiment: 0.3612\n",
      "---------------\n",
      "Entity mentionned: Saddam Hussein\n",
      "Tehran 's sworn enemy\n",
      "Sentiment: -0.5423\n",
      "---------------\n",
      "Entity mentionned: Hossein Dehghan\n",
      "Iranian Defence Minister\n",
      "Sentiment: 0.1027\n",
      "---------------\n",
      "Entity mentionned: Aoun\n",
      "who had accused the Saudis of holding his prime minister \" hostage \"\n",
      "Sentiment: -0.296\n",
      "---------------\n",
      "Entity mentionned: Isis\n",
      "which is our common enemy and the greatest threat to regional and worldwide peace and security \"\n",
      "Sentiment: 0.4939\n",
      "---------------\n",
      "Entity mentionned: Selahattin Demirtas\n",
      "the party 's charismatic leader\n",
      "Sentiment: 0.4019\n",
      "---------------\n",
      "Entity mentionned: Zaid al-Ali\n",
      "a legal expert and the author of the book The Struggle for Iraq 's Future\n",
      "Sentiment: -0.2023\n",
      "---------------\n",
      "Entity mentionned: Herve Ladsous\n",
      "the Under - Secretary - General for Peacekeeping Operations\n",
      "Sentiment: 0.4588\n",
      "---------------\n",
      "Entity mentionned: Erdogan\n",
      "who should apologize for comparing the Netherlands to fascists and Nazis\n",
      "Sentiment: -0.1027\n",
      "---------------\n",
      "Entity mentionned: Emad Jumaa\n",
      "a rebel commander popular among the hardline\n",
      "Sentiment: 0.296\n",
      "---------------\n",
      "Entity mentionned: John Kerry\n",
      "who is recovering from a cycling accident in Switzerland\n",
      "Sentiment: -0.4767\n",
      "---------------\n",
      "Entity mentionned: Bashar al-Assad\n",
      "Facebook pages that support the uprising against the government of the Syrian president\n",
      "Sentiment: 0.4019\n",
      "---------------\n",
      "Entity mentionned: Sheikh Abdullah bin Zayed al-Nahyan\n",
      "United Arab Emirates Foreign Minister\n",
      "Sentiment: 0.4215\n",
      "---------------\n",
      "Entity mentionned: John Kirby\n",
      "Pentagon spokesman Rear Admiral\n",
      "Sentiment: 0.3182\n",
      "---------------\n",
      "Entity mentionned: Abdullah Ocalan\n",
      "imprisoned\n",
      "Sentiment: -0.4588\n",
      "---------------\n",
      "Entity mentionned: Captain Alial-Kinani\n",
      "A Federal Police intelligence officer\n",
      "Sentiment: 0.4767\n"
     ]
    }
   ],
   "source": [
    "# Example some sentiment for some of the introductions\n",
    "\n",
    "subsample = np.random.choice(total_introductions, 100)\n",
    "for intro in subsample:\n",
    "    if intro['sentiment'] != 0:\n",
    "        print(\"---------------\")\n",
    "        print(\"Entity mentionned:\", intro['person'])\n",
    "        print(intro['text'])\n",
    "        print(\"Sentiment:\", intro['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a 2-dimensional object containing sentiment per entity, per source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ent_source_sent = {}\n",
    "\n",
    "for intro in total_introductions:\n",
    "    p = intro['person']\n",
    "    s = intro['source']\n",
    "    if p not in ent_source_sent:\n",
    "        ent_source_sent[p] = {}\n",
    "    if s not in ent_source_sent[p]:\n",
    "        ent_source_sent[p][s] = []\n",
    "    ent_source_sent[p][s].append(intro['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbc.co.uk': [0.0516, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.3182, -0.5994, -0.5994, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0], 'cnn.com': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0516, 0.0, 0.0, 0.0, -0.5994, -0.3818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.7096, -0.7096, 0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.0, 0.0, 0.0, -0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779], 'theguardian.com': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.7096, 0.0, -0.1531, 0.0], 'middleeasteye.net': [-0.1531, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.4404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3612, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reuters.com': [-0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.5994, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3612, -0.3612, 0.0, 0.0, 0.0, 0.0, -0.5106, 0.0, 0.0, 0.0, -0.3818, 0.0, 0.3182, 0.4404, 0.0, 0.3182, 0.4404, 0.0, -0.4404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3182, -0.3182, -0.5994, 0.0, -0.4588, 0.0, 0.0, -0.6808, 0.0, -0.4767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4404, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6124, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779, 0.0, -0.1779, -0.1531, -0.5994, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.128, 0.0, 0.0, 0.0], 'rt.com': [0.5574, 0.5574, 0.0, 0.0, 0.0, -0.5994, 0.0, -0.5994, -0.5994, 0.0, 0.0, 0.0, 0.0, -0.8316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6908], 'latimes.com': [0.0, 0.0], 'independent.co.uk': [-0.1531, 0.0, -0.0258, -0.1531, -0.6597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779, 0.0, 0.0, -0.2023, 0.0, -0.2023, 0.0, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, -0.2023, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'aljazeera.com': [-0.3182, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, -0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0516, -0.0516, -0.1531, 0.0, 0.0, -0.4404, -0.4404], 'france24.com': [-0.3182, 0.0, -0.6705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.5023, 0.0, 0.0, 0.0, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.743, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.4767, -0.5994, -0.9136, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5106, -0.6808, -0.3818, 0.0, 0.0, 0.0, 0.0, 0.3182, 0.4404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, -0.6249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5023, 0.0, 0.0, 0.5023, 0.0258, 0.0258, 0.0, -0.1531, -0.1531, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779, -0.1531, 0.0, -0.4019, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.3818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0], 'aa.com.tr': [0.0, -0.5994, -0.4019, 0.0, 0.0, 0.0, -0.5994, 0.0, -0.5994, 0.0, 0.0, 0.4588, -0.5994, 0.0, 0.0, 0.0, -0.7184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'nytimes.com': [0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.5574, 0.0, 0.0, 0.0, 0.0], 'ap.org': [0.0, -0.1531, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5709, 0.0, 0.0, 0.0, 0.0], 'chinadaily.com.cn': [0.0, 0.0], 'telegraph.co.uk': [0.4019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3182, 0.4404, -0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.3182, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3612, 0.2023, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'foxnews.com': [0.0, 0.5709, -0.5994, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, -0.1531, 0.0, -0.1531, 0.0, -0.5994, 0.0, 0.0, -0.1531, -0.6249, 0.0, -0.6249, 0.0, -0.6249, -0.5574, -0.8402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.2732, 0.0, -0.4939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0], 'allafrica.com': [-0.5994], 'washingtonpost.com': [0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.5859], 'bloomberg.com': [-0.5994, 0.0, 0.0, -0.2023, 0.0, -0.4404, -0.1531, -0.1531, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# An example of how one entity (a city) is described by different sources\n",
    "\n",
    "print(ent_source_sent['Aleppo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will keep a total of 7852  /  25128 in our dataset\n",
      "We have  22 sources:  ['chinadaily.com.cn', 'ap.org', 'latimes.com', 'bbc.co.uk', 'rt.com', 'allafrica.com', 'businessinsider.in', 'independent.co.uk', 'aljazeera.com', 'middleeasteye.net', 'nytimes.com', 'aa.com.tr', 'cnn.com', 'telegraph.co.uk', 'foxnews.com', 'theguardian.com', 'washingtonpost.com', 'reuters.com', 'techcrunch.com', 'france24.com', 'bloomberg.com', 'wikinews.org']\n"
     ]
    }
   ],
   "source": [
    "# We get rid of entities that don't contain enough data\n",
    "\n",
    "entities_kept = []\n",
    "\n",
    "for entity in ent_source_sent.keys():\n",
    "    sentiments = ent_source_sent[entity]\n",
    "    total_size = sum([len(sentiments[source]) for source in sentiments.keys()])\n",
    "    if total_size >= 3:\n",
    "        entities_kept.append(entity)\n",
    "        \n",
    "print(\"We will keep a total of\", len(entities_kept), \" / \", len(ent_source_sent.keys()) ,\"in our dataset\")\n",
    "\n",
    "sources = set([])\n",
    "for entity in entities_kept:\n",
    "    sources|= set(ent_source_sent[entity].keys())\n",
    "sources = list(sources)\n",
    "\n",
    "print(\"We have \", len(sources), \"sources: \", sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create the array we will use in our sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We allocated some sentiment in this matrix, the repartition is: Counter({0: 19062, 1: 3650, -1: 2669})\n"
     ]
    }
   ],
   "source": [
    "# Parameters: changing these affects the results you get\n",
    "Pos_neg_ratio = 2.0\n",
    "overall_ratio = 0.15\n",
    "pos_threshold = 0.15\n",
    "neg_threshold = -0.15\n",
    "\n",
    "N = len(entities_kept)\n",
    "M = len(sources)\n",
    "A = np.zeros((N, M))\n",
    "\n",
    "sentiment_counts = Counter()\n",
    "\n",
    "source2j = {source: j for j, source in enumerate(sources)}\n",
    "\n",
    "for i, entity in enumerate(entities_kept):\n",
    "    for source in ent_source_sent[entity].keys():\n",
    "        sent_array = np.array(ent_source_sent[entity][source])\n",
    "        N_pos = float(len(np.where(sent_array > pos_threshold)[0]))\n",
    "        N_neg = float(len(np.where(sent_array < neg_threshold)[0]))\n",
    "        T = float(len(sent_array))\n",
    "        aggregate_sentiment = 0\n",
    "        if N_pos > Pos_neg_ratio*N_neg and N_pos > overall_ratio*T:\n",
    "            aggregate_sentiment = 1\n",
    "        elif N_neg > Pos_neg_ratio*N_pos and N_neg > overall_ratio*T:\n",
    "            aggregate_sentiment = -1\n",
    "        j = source2j[source]\n",
    "        \n",
    "        A[i,j] = aggregate_sentiment\n",
    "        \n",
    "        sentiment_counts[aggregate_sentiment] += 1\n",
    "\n",
    "print (\"We allocated some sentiment in this matrix, the repartition is:\", sentiment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model source similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code that uses this matrix (entities, sources) to compute\n",
    "# source similarity visible in bias of the way they describe entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import GraphLasso\n",
    "graph_lasso = GraphLasso(alpha=0.01)\n",
    "graph_lasso.fit(A)\n",
    "np.mean(graph_lasso.get_precision() > 0)\n",
    "\n",
    "for (i, j) in zip(*np.where(abs(graph_lasso.get_precision()) > 0)):\n",
    "    if i > j:\n",
    "        print(sources[i], sources[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ee227-py3",
   "language": "python",
   "name": "ee227-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "778194441efa4fe0ac005b5453b5c790": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
